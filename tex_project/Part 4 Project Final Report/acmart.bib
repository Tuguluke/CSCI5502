
@misc{ji_win-win_2022,
	title = {Win-{Win} {Cooperation}: {Bundling} {Sequence} and {Span} {Models} for {Named} {Entity} {Recognition}},
	shorttitle = {Win-{Win} {Cooperation}},
	url = {http://arxiv.org/abs/2207.03300},
	abstract = {For Named Entity Recognition (NER), sequence labeling-based and span-based paradigms are quite different. Previous research has demonstrated that the two paradigms have clear complementary advantages, but few models have attempted to leverage these advantages in a single NER model as far as we know. In our previous work, we proposed a paradigm known as Bundling Learning (BL) to address the above problem. The BL paradigm bundles the two NER paradigms, enabling NER models to jointly tune their parameters by weighted summing each paradigm's training loss. However, three critical issues remain unresolved: When does BL work? Why does BL work? Can BL enhance the existing state-of-the-art (SOTA) NER models? To address the first two issues, we implement three NER models, involving a sequence labeling-based model--SeqNER, a span-based NER model--SpanNER, and BL-NER that bundles SeqNER and SpanNER together. We draw two conclusions regarding the two issues based on the experimental results on eleven NER datasets from five domains. We then apply BL to five existing SOTA NER models to investigate the third issue, consisting of three sequence labeling-based models and two span-based models. Experimental results indicate that BL consistently enhances their performance, suggesting that it is possible to construct a new SOTA NER system by incorporating BL into the current SOTA system. Moreover, we find that BL reduces both entity boundary and type prediction errors. In addition, we compare two commonly used labeling tagging methods as well as three types of span semantic representations.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Ji, Bin and Li, Shasha and Yu, Jie and Ma, Jun and Liu, Huijun},
	month = jul,
	year = {2022},
	note = {arXiv:2207.03300 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/UYI22EYA/Ji et al. - 2022 - Win-Win Cooperation Bundling Sequence and Span Mo.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/LEJ3ADZU/2207.html:text/html},
}

@misc{smirnova_evaluation_2022,
	title = {Evaluation of {Embedding} {Models} for {Automatic} {Extraction} and {Classification} of {Acknowledged} {Entities} in {Scientific} {Documents}},
	url = {http://arxiv.org/abs/2206.10939},
	abstract = {Acknowledgments in scientific papers may give an insight into aspects of the scientific community, such as reward systems, collaboration patterns, and hidden research trends. The aim of the paper is to evaluate the performance of different embedding models for the task of automatic extraction and classification of acknowledged entities from the acknowledgment text in scientific papers. We trained and implemented a named entity recognition (NER) task using the Flair NLP-framework. The training was conducted using three default Flair NER models with two differently-sized corpora. The Flair Embeddings model trained on the larger training corpus showed the best accuracy of 0.77. Our model is able to recognize six entity types: funding agency, grant number, individuals, university, corporation and miscellaneous. The model works more precise for some entity types than the others, thus, individuals and grant numbers showed very good F1-Score over 0.9. Most of the previous works on acknowledgement analysis were limited by the manual evaluation of data and therefore by the amount of processed data. This model can be applied for the comprehensive analysis of the acknowledgement texts and may potentially make a great contribution to the field of automated acknowledgement analysis.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Smirnova, Nina and Mayr, Philipp},
	month = jun,
	year = {2022},
	note = {arXiv:2206.10939 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Digital Libraries},
	annote = {Comment: Accepted workshop paper at EEKE2022 Workshop(JCDL2022)},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/FA3WWBX9/Smirnova and Mayr - 2022 - Evaluation of Embedding Models for Automatic Extra.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/9P5YL7DB/2206.html:text/html},
}

@misc{zhou_deep_2022,
	title = {Deep {Clustering} with {Features} from {Self}-{Supervised} {Pretraining}},
	url = {http://arxiv.org/abs/2207.13364},
	abstract = {A deep clustering model conceptually consists of a feature extractor that maps data points to a latent space, and a clustering head that groups data points into clusters in the latent space. Although the two components used to be trained jointly in an end-to-end fashion, recent works have proved it beneficial to train them separately in two stages. In the first stage, the feature extractor is trained via self-supervised learning, which enables the preservation of the cluster structures among the data points. To preserve the cluster structures even better, we propose to replace the first stage with another model that is pretrained on a much larger dataset via self-supervised learning. The method is simple and might suffer from domain shift. Nonetheless, we have empirically shown that it can achieve superior clustering performance. When a vision transformer (ViT) architecture is used for feature extraction, our method has achieved clustering accuracy 94.0\%, 55.6\% and 97.9\% on CIFAR-10, CIFAR-100 and STL-10 respectively. The corresponding previous state-of-the-art results are 84.3\%, 47.7\% and 80.8\%. Our code will be available online with the publication of the paper.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Zhou, Xingzhi and Zhang, Nevin L.},
	month = jul,
	year = {2022},
	note = {arXiv:2207.13364 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/T88JZ2TH/Zhou and Zhang - 2022 - Deep Clustering with Features from Self-Supervised.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/6XSFI2ZX/2207.html:text/html},
}

@misc{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {arXiv:1706.03762 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: 15 pages, 5 figures},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/K9A3JL6T/Vaswani et al. - 2017 - Attention Is All You Need.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/M7PYHB6I/1706.html:text/html},
}

@misc{decorte_jobbert_2021,
	title = {{JobBERT}: {Understanding} {Job} {Titles} through {Skills}},
	shorttitle = {{JobBERT}},
	url = {http://arxiv.org/abs/2109.09605},
	abstract = {Job titles form a cornerstone of today's human resources (HR) processes. Within online recruitment, they allow candidates to understand the contents of a vacancy at a glance, while internal HR departments use them to organize and structure many of their processes. As job titles are a compact, convenient, and readily available data source, modeling them with high accuracy can greatly benefit many HR tech applications. In this paper, we propose a neural representation model for job titles, by augmenting a pre-trained language model with co-occurrence information from skill labels extracted from vacancies. Our JobBERT method leads to considerable improvements compared to using generic sentence encoders, for the task of job title normalization, for which we release a new evaluation benchmark.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Decorte, Jens-Joris and Van Hautte, Jeroen and Demeester, Thomas and Develder, Chris},
	month = sep,
	year = {2021},
	note = {arXiv:2109.09605 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted to the International workshop on Fair, Effective And Sustainable Talent management using data science (FEAST) as part of ECML-PKDD 2021},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/DRC5LXB7/Decorte et al. - 2021 - JobBERT Understanding Job Titles through Skills.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/ZEFYX29Y/2109.html:text/html},
}

@misc{breidenbach_implicit_2021,
	title = {Implicit {Gender} {Bias} in {Computer} {Science} -- {A} {Qualitative} {Study}},
	url = {http://arxiv.org/abs/2107.01624},
	abstract = {Gender diversity in the tech sector is - not yet? - sufficient to create a balanced ratio of men and women. For many women, access to computer science is hampered by socialization-related, social, cultural and structural obstacles. The so-called implicit gender bias has a great influence in this respect. The lack of contact in areas of computer science makes it difficult to develop or expand potential interests. Female role models as well as more transparency of the job description should help women to promote their - possible - interest in the job description. However, gender diversity can also be promoted and fostered through adapted measures by leaders.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Breidenbach, Aurélie and Mahlow, Caroline and Schreiber, Andreas},
	month = jul,
	year = {2021},
	note = {arXiv:2107.01624 [cs]},
	keywords = {Computer Science - Computers and Society, Computer Science - Software Engineering, K.4.2, K.7.0},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/XVIYDQJG/Breidenbach et al. - 2021 - Implicit Gender Bias in Computer Science -- A Qual.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/5KF8FC5P/2107.html:text/html},
}

@misc{xue_contextual_2022,
	title = {Contextual {Text} {Block} {Detection} towards {Scene} {Text} {Understanding}},
	url = {http://arxiv.org/abs/2207.12955},
	abstract = {Most existing scene text detectors focus on detecting characters or words that only capture partial text messages due to missing contextual information. For a better understanding of text in scenes, it is more desired to detect contextual text blocks (CTBs) which consist of one or multiple integral text units (e.g., characters, words, or phrases) in natural reading order and transmit certain complete text messages. This paper presents contextual text detection, a new setup that detects CTBs for better understanding of texts in scenes. We formulate the new setup by a dual detection task which first detects integral text units and then groups them into a CTB. To this end, we design a novel scene text clustering technique that treats integral text units as tokens and groups them (belonging to the same CTB) into an ordered token sequence. In addition, we create two datasets SCUT-CTW-Context and ReCTS-Context to facilitate future research, where each CTB is well annotated by an ordered sequence of integral text units. Further, we introduce three metrics that measure contextual text detection in local accuracy, continuity, and global accuracy. Extensive experiments show that our method accurately detects CTBs which effectively facilitates downstream tasks such as text classification and translation. The project is available at https://sg-vilab.github.io/publication/xue2022contextual/.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Xue, Chuhui and Huang, Jiaxing and Lu, Shijian and Wang, Changhu and Bai, Song},
	month = jul,
	year = {2022},
	note = {arXiv:2207.12955 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Accepted by ECCV2022},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/QPUZHFQA/Xue et al. - 2022 - Contextual Text Block Detection towards Scene Text.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/7MQ9P5SU/2207.html:text/html},
}

@misc{pardos_map_2018,
	title = {A {Map} of {Knowledge}},
	url = {http://arxiv.org/abs/1811.07974},
	abstract = {Knowledge representation has gained in relevance as data from the ubiquitous digitization of behaviors amass and academia and industry seek methods to understand and reason about the information they encode. Success in this pursuit has emerged with data from natural language, where skip-grams and other linear connectionist models of distributed representation have surfaced scrutable relational structures which have also served as artifacts of anthropological interest. Natural language is, however, only a fraction of the big data deluge. Here we show that latent semantic structure, comprised of elements from digital records of our interactions, can be informed by behavioral data and that domain knowledge can be extracted from this structure through visualization and a novel mapping of the literal descriptions of elements onto this behaviorally informed representation. We use the course enrollment behaviors of 124,000 students at a public university to learn vector representations of its courses. From these behaviorally informed representations, a notable 88\% of course attribute information were recovered (e.g., department and division), as well as 40\% of course relationships constructed from prior domain knowledge and evaluated by analogy (e.g., Math 1B is to Math H1B as Physics 7B is to Physics H7B). To aid in interpretation of the learned structure, we create a semantic interpolation, translating course vectors to a bag-of-words of their respective catalog descriptions. We find that the representations learned from enrollments resolved course vectors to a level of semantic fidelity exceeding that of their catalog descriptions, depicting a vector space of high conceptual rationality. We end with a discussion of the possible mechanisms by which this knowledge structure may be informed and its implications for data science.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Pardos, Zachary A. and Nam, Andrew Joo Hun},
	month = nov,
	year = {2018},
	note = {arXiv:1811.07974 [cs]},
	keywords = {Computer Science - Computers and Society},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/QBLJH4K4/Pardos and Nam - 2018 - A Map of Knowledge.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/6JMRA4AW/1811.html:text/html},
}

@misc{wang_enhancing_2022,
	title = {Enhancing {Document}-level {Relation} {Extraction} by {Entity} {Knowledge} {Injection}},
	url = {http://arxiv.org/abs/2207.11433},
	abstract = {Document-level relation extraction (RE) aims to identify the relations between entities throughout an entire document. It needs complex reasoning skills to synthesize various knowledge such as coreferences and commonsense. Large-scale knowledge graphs (KGs) contain a wealth of real-world facts, and can provide valuable knowledge to document-level RE. In this paper, we propose an entity knowledge injection framework to enhance current document-level RE models. Specifically, we introduce coreference distillation to inject coreference knowledge, endowing an RE model with the more general capability of coreference reasoning. We also employ representation reconciliation to inject factual knowledge and aggregate KG representations and document representations into a unified space. The experiments on two benchmark datasets validate the generalization of our entity knowledge injection framework and the consistent improvement to several document-level RE models.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Wang, Xinyi and Wang, Zitao and Sun, Weijian and Hu, Wei},
	month = jul,
	year = {2022},
	note = {arXiv:2207.11433 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted in the 21th International Semantic Web Conference (ISWC 2022)},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/862FNVPF/Wang et al. - 2022 - Enhancing Document-level Relation Extraction by En.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/W8SLS97Z/2207.html:text/html},
}

@misc{wang_person-job_2022,
	title = {Person-job fit estimation from candidate profile and related recruitment history with co-attention neural networks},
	url = {http://arxiv.org/abs/2206.09116},
	abstract = {Existing online recruitment platforms depend on automatic ways of conducting the person-job fit, whose goal is matching appropriate job seekers with job positions. Intuitively, the previous successful recruitment records contain important information, which should be helpful for the current person-job fit. Existing studies on person-job fit, however, mainly focus on calculating the similarity between the candidate resumes and the job postings on the basis of their contents, without taking the recruiters' experience (i.e., historical successful recruitment records) into consideration. In this paper, we propose a novel neural network approach for person-job fit, which estimates person-job fit from candidate profile and related recruitment history with co-attention neural networks (named PJFCANN). Specifically, given a target resume-job post pair, PJFCANN generates local semantic representations through co-attention neural networks and global experience representations via graph neural networks. The final matching degree is calculated by combining these two representations. In this way, the historical successful recruitment records are introduced to enrich the features of resumes and job postings and strengthen the current matching process. Extensive experiments conducted on a large-scale recruitment dataset verify the effectiveness of PJFCANN compared with several state-of-the-art baselines. The codes are released at: https://github.com/CCIIPLab/PJFCANN.},
	urldate = {2022-07-28},
	publisher = {arXiv},
	author = {Wang, Ziyang and Wei, Wei and Xu, Chenwei and Xu, Jun and Mao, Xian-Ling},
	month = jun,
	year = {2022},
	note = {arXiv:2206.09116 [cs]},
	keywords = {Computer Science - Information Retrieval},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/FALCLIJ6/Wang et al. - 2022 - Person-job fit estimation from candidate profile a.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/HUG2KSE6/2206.html:text/html},
}

@inproceedings{gutierrez_augury_2016,
	title = {{AUGURY}: {A} time-series based application for the analysis and forecasting of system and network performance metrics},
	shorttitle = {{AUGURY}},
	url = {http://arxiv.org/abs/1607.08344},
	doi = {10.1109/SYNASC.2016.062},
	abstract = {This paper presents AUGURY, an application for the analysis of monitoring data from computers, servers or cloud infrastructures. The analysis is based on the extraction of patterns and trends from historical data, using elements of time-series analysis. The purpose of AUGURY is to aid a server administrator by forecasting the behaviour and resource usage of specific applications and in presenting a status report in a concise manner. AUGURY provides tools for identifying network traffic congestion and peak usage times, and for making memory usage projections. The application data processing specialises in two tasks: the parametrisation of the memory usage of individual applications and the extraction of the seasonal component from network traffic data. AUGURY uses a different underlying assumption for each of these two tasks. With respect to the memory usage, a limited number of single-valued parameters are assumed to be sufficient to parameterize any application being hosted on the server. Regarding the network traffic data, long-term patterns, such as hourly or daily exist and are being induced by work-time schedules and automatised administrative jobs. In this paper, the implementation of each of the two tasks is presented, tested using locally-generated data, and applied to data from weather forecasting applications hosted on a web server. This data is used to demonstrate the insight that AUGURY can add to the monitoring of server and cloud infrastructures.},
	urldate = {2022-07-28},
	booktitle = {2016 18th {International} {Symposium} on {Symbolic} and {Numeric} {Algorithms} for {Scientific} {Computing} ({SYNASC})},
	author = {Gutierrez, Nicolas and Wiesinger-Widi, Manuela},
	month = sep,
	year = {2016},
	note = {arXiv:1607.08344 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing, Computer Science - Performance},
	pages = {351--358},
	annote = {Comment: 8 pages, 9 figures, submitted to SYNASC2016},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/8VTZ6AVI/Gutierrez and Wiesinger-Widi - 2016 - AUGURY A time-series based application for the an.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/Z72247VX/1607.html:text/html},
}

@article{atalay_mapping_nodate,
	title = {Mapping {Text} to {Occupational} {Characteristics}; {Mapping} {Job} {Titles} to {SOC} {Codes}; {Mapping} {Job} {Titles} to {OCC} {Codes}},
	abstract = {In this document, we outline and justify the procedures we use ﬁrst, to convert the text from job ads to diﬀerent occupational characteristics, and second to map the job title to either an SOC code or an OCC code. For the ﬁrst task of constructing mappings from job ad text to occupational characteristics, we rely on three complementary approaches: i) mappings based on our own judgment of the meaning of words and phrases, ii) mappings based on a continuous bag of words model which we have constructed, and iii) mappings used in previous papers. We describe these three approaches in order. Then, we discuss our methods to construct a mapping between job titles, SOC codes, and OCC codes.},
	language = {en},
	author = {Atalay, Enghin and Phongthiengtham, Phai and Sotelo, Sebastian},
	pages = {11},
	file = {Atalay et al. - Mapping Text to Occupational Characteristics\; Mapp.pdf:/Users/abulitibu.tuguluke/Zotero/storage/T6Y367RM/Atalay et al. - Mapping Text to Occupational Characteristics\; Mapp.pdf:application/pdf},
}

@misc{mikolov_efficient_2013,
	title = {Efficient {Estimation} of {Word} {Representations} in {Vector} {Space}},
	url = {http://arxiv.org/abs/1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	urldate = {2022-08-02},
	publisher = {arXiv},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	month = sep,
	year = {2013},
	note = {arXiv:1301.3781 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/4LHFSQ2S/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/K6W6UPJZ/1301.html:text/html},
}

@misc{nanjundan_identifying_2019,
	title = {Identifying the number of clusters for {K}-{Means}: {A} hypersphere density based approach},
	shorttitle = {Identifying the number of clusters for {K}-{Means}},
	url = {http://arxiv.org/abs/1912.00643},
	abstract = {Application of K-Means algorithm is restricted by the fact that the number of clusters should be known beforehand. Previously suggested methods to solve this problem are either ad hoc or require parametric assumptions and complicated calculations. The proposed method aims to solve this conundrum by considering cluster hypersphere density as the factor to determine the number of clusters in the given dataset. The density is calculated by assuming a hypersphere around the cluster centroid for n-different number of clusters. The calculated values are plotted against their corresponding number of clusters and then the optimum number of clusters is obtained after assaying the elbow region of the graph. The method is simple, easy to comprehend, and provides robust and reliable results.},
	urldate = {2022-08-02},
	publisher = {arXiv},
	author = {Nanjundan, Sukavanan and Sankaran, Shreeviknesh and Arjun, C. R. and Anand, G. Paavai},
	month = dec,
	year = {2019},
	note = {arXiv:1912.00643 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 5 pages, 13 figures, International Conference on Computers, Communication and Signal Processing - 2019},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/35SG4PYX/Nanjundan et al. - 2019 - Identifying the number of clusters for K-Means A .pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/TW68W9N4/1912.html:text/html},
}

@misc{capo_efficient_2018,
	title = {An efficient {K} -means clustering algorithm for massive data},
	url = {http://arxiv.org/abs/1801.02949},
	abstract = {The analysis of continously larger datasets is a task of major importance in a wide variety of scientific fields. In this sense, cluster analysis algorithms are a key element of exploratory data analysis, due to their easiness in the implementation and relatively low computational cost. Among these algorithms, the K -means algorithm stands out as the most popular approach, besides its high dependency on the initial conditions, as well as to the fact that it might not scale well on massive datasets. In this article, we propose a recursive and parallel approximation to the K -means algorithm that scales well on both the number of instances and dimensionality of the problem, without affecting the quality of the approximation. In order to achieve this, instead of analyzing the entire dataset, we work on small weighted sets of points that mostly intend to extract information from those regions where it is harder to determine the correct cluster assignment of the original instances. In addition to different theoretical properties, which deduce the reasoning behind the algorithm, experimental results indicate that our method outperforms the state-of-the-art in terms of the trade-off between number of distance computations and the quality of the solution obtained.},
	urldate = {2022-08-02},
	publisher = {arXiv},
	author = {Capó, Marco and Pérez, Aritz and Lozano, Jose A.},
	month = jan,
	year = {2018},
	note = {arXiv:1801.02949 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/KCVEJAB4/Capó et al. - 2018 - An efficient K -means clustering algorithm for mas.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/2JDF694M/1801.html:text/html},
}

@misc{lee_better_2022,
	title = {Better {Reasoning} {Behind} {Classification} {Predictions} with {BERT} for {Fake} {News} {Detection}},
	url = {http://arxiv.org/abs/2207.11562},
	abstract = {Fake news detection has become a major task to solve as there has been an increasing number of fake news on the internet in recent years. Although many classification models have been proposed based on statistical learning methods showing good results, reasoning behind the classification performances may not be enough. In the self-supervised learning studies, it has been highlighted that a quality of representation (embedding) space matters and directly affects a downstream task performance. In this study, a quality of the representation space is analyzed visually and analytically in terms of linear separability for different classes on a real and fake news dataset. To further add interpretability to a classification model, a modification of Class Activation Mapping (CAM) is proposed. The modified CAM provides a CAM score for each word token, where the CAM score on a word token denotes a level of focus on that word token to make the prediction. Finally, it is shown that the naive BERT model topped with a learnable linear layer is enough to achieve robust performance while being compatible with CAM.},
	urldate = {2022-08-02},
	publisher = {arXiv},
	author = {Lee, Daesoo},
	month = jul,
	year = {2022},
	note = {arXiv:2207.11562 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/PMQLVIPJ/Lee - 2022 - Better Reasoning Behind Classification Predictions.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/DUJ76TB9/2207.html:text/html},
}

@misc{hochstenbach_event_2022,
	title = {Event {Notifications} in {Value}-{Adding} {Networks}},
	url = {http://arxiv.org/abs/2208.00665},
	abstract = {Linkages between research outputs are crucial in the scholarly knowledge graph. They include online citations, but also links between versions that differ according to various dimensions and links to resources that were used to arrive at research results. In current scholarly communication systems this information is only made available post factum and is obtained via elaborate batch processing. In this paper we report on work aimed at making linkages available in real-time, in which an alternative, decentralised scholarly communication network is considered that consists of interacting data nodes that host artifacts and service nodes that add value to artifacts. The first result of this work, the "Event Notifications in Value-Adding Networks" specification, details interoperability requirements for the exchange real-time life-cycle information pertaining to artifacts using Linked Data Notifications. In an experiment, we applied our specification to one particular use-case: distributing Scholix data-literature links to a network of Belgian institutional repositories by a national service node. The results of our experiment confirm the potential of our approach and provide a framework to create a network of interacting nodes implementing the core scholarly functions (registration, certification, awareness and archiving) in a decentralized and decoupled way.},
	urldate = {2022-08-02},
	publisher = {arXiv},
	author = {Hochstenbach, Patrick and Van de Sompel, Herbert and Sande, Miel Vander and Dedecker, Ruben and Verborgh, Ruben},
	month = aug,
	year = {2022},
	note = {arXiv:2208.00665 [cs]},
	keywords = {Computer Science - Digital Libraries},
	annote = {Comment: 12 pages, 2 figures, Accepted at the 26th International Conference on Theory and Practice of Digital Libraries, Padua, Italy},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/KLZUEUVN/Hochstenbach et al. - 2022 - Event Notifications in Value-Adding Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/A6FGJEMM/2208.html:text/html},
}

@misc{bahaj_kg-nsf_2022,
	title = {{KG}-{NSF}: {Knowledge} {Graph} {Completion} with a {Negative}-{Sample}-{Free} {Approach}},
	shorttitle = {{KG}-{NSF}},
	url = {http://arxiv.org/abs/2207.14617},
	abstract = {Knowledge Graph (KG) completion is an important task that greatly benefits knowledge discovery in many fields (e.g. biomedical research). In recent years, learning KG embeddings to perform this task has received considerable attention. Despite the success of KG embedding methods, they predominantly use negative sampling, resulting in increased computational complexity as well as biased predictions due to the closed world assumption. To overcome these limitations, we propose {\textbackslash}textbf\{KG-NSF\}, a negative sampling-free framework for learning KG embeddings based on the cross-correlation matrices of embedding vectors. It is shown that the proposed method achieves comparable link prediction performance to negative sampling-based methods while converging much faster.},
	urldate = {2022-08-02},
	publisher = {arXiv},
	author = {Bahaj, Adil and Lhazmir, Safae and Ghogho, Mounir},
	month = jul,
	year = {2022},
	note = {arXiv:2207.14617 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
	annote = {Comment: 16 pages, 7 figures},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/F7M5D568/Bahaj et al. - 2022 - KG-NSF Knowledge Graph Completion with a Negative.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/5PVW5RXB/2207.html:text/html},
}

@misc{rozanec_enriching_2022,
	title = {Enriching {Artificial} {Intelligence} {Explanations} with {Knowledge} {Fragments}},
	url = {http://arxiv.org/abs/2204.05579},
	abstract = {Artificial Intelligence models are increasingly used in manufacturing to inform decision-making. Responsible decision-making requires accurate forecasts and an understanding of the models' behavior. Furthermore, the insights into models' rationale can be enriched with domain knowledge. This research builds explanations considering feature rankings for a particular forecast, enriching them with media news entries, datasets' metadata, and entries from the Google Knowledge Graph. We compare two approaches (embeddings-based and semantic-based) on a real-world use case regarding demand forecasting.},
	urldate = {2022-08-02},
	publisher = {arXiv},
	author = {Rožanec, Jože M. and Trajkova, Elena and Novalija, Inna and Zajec, Patrik and Kenda, Klemen and Fortuna, Blaž and Mladenić, Dunja},
	month = apr,
	year = {2022},
	note = {arXiv:2204.05579 [cs]},
	keywords = {Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/DSXZ452V/Rožanec et al. - 2022 - Enriching Artificial Intelligence Explanations wit.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/6W53FM7T/2204.html:text/html},
}

@misc{wondimu_interactive_2022,
	title = {Interactive {Machine} {Learning}: {A} {State} of the {Art} {Review}},
	shorttitle = {Interactive {Machine} {Learning}},
	url = {http://arxiv.org/abs/2207.06196},
	abstract = {Machine learning has proved useful in many software disciplines, including computer vision, speech and audio processing, natural language processing, robotics and some other fields. However, its applicability has been significantly hampered due its black-box nature and significant resource consumption. Performance is achieved at the expense of enormous computational resource and usually compromising the robustness and trustworthiness of the model. Recent researches have been identifying a lack of interactivity as the prime source of these machine learning problems. Consequently, interactive machine learning (iML) has acquired increased attention of researchers on account of its human-in-the-loop modality and relatively efficient resource utilization. Thereby, a state-of-the-art review of interactive machine learning plays a vital role in easing the effort toward building human-centred models. In this paper, we provide a comprehensive analysis of the state-of-the-art of iML. We analyze salient research works using merit-oriented and application/task oriented mixed taxonomy. We use a bottom-up clustering approach to generate a taxonomy of iML research works. Research works on adversarial black-box attacks and corresponding iML based defense system, exploratory machine learning, resource constrained learning, and iML performance evaluation are analyzed under their corresponding theme in our merit-oriented taxonomy. We have further classified these research works into technical and sectoral categories. Finally, research opportunities that we believe are inspiring for future work in iML are discussed thoroughly.},
	urldate = {2022-08-02},
	publisher = {arXiv},
	author = {Wondimu, Natnael A. and Buche, Cédric and Visser, Ubbo},
	month = jul,
	year = {2022},
	note = {arXiv:2207.06196 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/abulitibu.tuguluke/Zotero/storage/MEQT679Y/Wondimu et al. - 2022 - Interactive Machine Learning A State of the Art R.pdf:application/pdf;arXiv.org Snapshot:/Users/abulitibu.tuguluke/Zotero/storage/6QPBCDT7/2207.html:text/html},
}
